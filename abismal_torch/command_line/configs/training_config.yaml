trainer:
  accelerator: "cpu"
  max_steps: 30 #30_000
  deterministic: true
  log_every_n_steps: 10
  check_val_every_n_epoch: 1

optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 0.001
    betas: [0.9, 0.9]
    eps: 1e-9
    amsgrad: false
